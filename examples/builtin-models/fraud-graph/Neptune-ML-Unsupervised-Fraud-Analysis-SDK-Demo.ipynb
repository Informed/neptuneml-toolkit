{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fa3a41d",
   "metadata": {},
   "source": [
    "# Neptune ML Unsupervised Learning for Fraud Analysis\n",
    "\n",
    "This notebook uses Neptune ML to train a model on a fraud graph data model and extract embeddings for visualizatio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab1c3a4",
   "metadata": {},
   "source": [
    "## Checking that we are ready to run Neptune ML\n",
    "\n",
    "The Neptune ML Toolkit is a python package that provides a SDK for graph machine learning with Neptune ML. You can also use jupyter magics `%%neptune_ml` from a jupyter notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ac8224",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --pre neptuneml_toolkit\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1850d0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import JSON\n",
    "from neptuneml_toolkit import NeptuneMLClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fa26e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune_ml = NeptuneMLClient()\n",
    "neptune_ml.check_enabled()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521369ef",
   "metadata": {},
   "source": [
    "## Exporting the data to S3 for the machine learning workflow\n",
    "\n",
    "Since we're using SageMaker as the ML infrastructure our data has to be in a S3 bucket where SageMaker can access it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33fef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket_uri=\"s3://<Replace-with-your-s3-bucket-name>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544622fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_params={ \n",
    "\"command\": \"export-pg\", \n",
    "\"params\": { \"endpoint\": neptune_ml.get_host(),\n",
    "            \"profile\": \"neptune_ml\",\n",
    "            \"cloneCluster\": False\n",
    "            }, \n",
    "\"outputS3Path\": f'{s3_bucket_uri}/neptune-export',\n",
    "\"additionalParams\": {},\n",
    "\"jobSize\": \"medium\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b396a6",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "export_results = neptune_ml.create_data_export_job(params=export_params, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faac66c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "training_data_config = neptune_ml.get_training_data_configuration(export_results[\"jobId\"])\n",
    "JSON(training_data_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52349d1",
   "metadata": {},
   "source": [
    "###  Selecting Node Properties for ML Features\n",
    "\n",
    "We can choose which properties to use as features for machine learning and how those features are encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784c36d0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Update node features for training\n",
    "nodes = [{'file_name': 'nodes/Account.consolidated.csv',\n",
    "    'separator': ',',\n",
    "    'node': ['~id', 'Account'],\n",
    "    'features': [\n",
    "     {'feature': ['component', 'component', 'category']},\n",
    "     ]},\n",
    "   {'file_name': 'nodes/EmailAddress.consolidated.csv',\n",
    "    'separator': ',',\n",
    "    'node': ['~id', 'EmailAddress']},\n",
    "   {'file_name': 'nodes/Address.consolidated.csv',\n",
    "    'separator': ',',\n",
    "    'node': ['~id', 'Address']},\n",
    "   {'file_name': 'nodes/DateOfBirth.consolidated.csv',\n",
    "    'separator': ',',\n",
    "    'node': ['~id', 'DateOfBirth'],\n",
    "    'features': [{'feature': ['value', 'value', 'datetime'],\n",
    "     'datetime_parts': ['year', 'month', 'weekday', 'hour']}]},\n",
    "   {'file_name': 'nodes/Transaction.consolidated.csv',\n",
    "    'separator': ',',\n",
    "    'node': ['~id', 'Transaction'],\n",
    "    'features': [\n",
    "        {'feature': ['amount', 'amount', 'numerical'],\n",
    "         'norm': 'min-max',\n",
    "         'imputer': 'median'},\n",
    "        {'feature': ['created', 'created', 'datetime'],\n",
    "         'datetime_parts': ['year', 'month', 'weekday', 'hour']}]},\n",
    "   {'file_name': 'nodes/PhoneNumber.consolidated.csv',\n",
    "    'separator': ',',\n",
    "    'node': ['~id', 'PhoneNumber']},\n",
    "   {'file_name': 'nodes/IpAddress.consolidated.csv',\n",
    "    'separator': ',',\n",
    "    'node': ['~id', 'IpAddress']},\n",
    "   {'file_name': 'nodes/Merchant.consolidated.csv',\n",
    "    'separator': ',',\n",
    "    'node': ['~id', 'Merchant']}\n",
    "]\n",
    "\n",
    "training_data_config['graph']['nodes'] = nodes\n",
    "JSON(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660f9cc0",
   "metadata": {},
   "source": [
    "# ML Data Processing\n",
    "\n",
    "Since we're using DGL as the Graph ML framework, we will process the export data in the S3 bucket to create a graph representation in DGL format and do the feature engineering we specified earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dde0bb",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data_processing_output = neptune_ml.create_data_processing_job(inputDataS3Location=export_results['outputS3Uri'],\n",
    "                                      configFileName='training-data-configuration.json',\n",
    "                                      processedDataS3Location= '{}/preloading'.format(s3_bucket_uri),\n",
    "                                      trainingDataConfiguration=training_data_config,\n",
    "                                      wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7ff11c",
   "metadata": {},
   "source": [
    "# ML Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1365a3f8",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model_training_output = neptune_ml.create_model_training_job(dataProcessingJobId=data_processing_output[\"id\"],\n",
    "                                     trainModelS3Location='{}/training'.format(s3_bucket_uri),\n",
    "                                     wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16c588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbddcd36",
   "metadata": {},
   "source": [
    "## Get Trained Model Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a2cf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = neptune_ml.get_embeddings(model_training_output[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd86d8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping, embedding_index_mapping = neptune_ml.get_node_index_mapping(model_training_output[\"id\"])\n",
    "account_embeddings = embeddings[embedding_index_mapping['Account']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea12b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(account_embeddings.shape)\n",
    "account_embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9733b248",
   "metadata": {},
   "source": [
    "## Reduce embedding dimension for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3038cfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "dim_reducer= UMAP(n_components=2)\n",
    "account_embeddings_reduced_dim = dim_reducer.fit_transform(account_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e32c84c",
   "metadata": {},
   "source": [
    "## Visualize generated embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fb43bc",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513784cc",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "iso = IsolationForest()\n",
    "iso.n_features_in_ = 128\n",
    "y_pred = iso.fit(account_embeddings).predict(account_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81661ad",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot()\n",
    "fig.suptitle(\"Visualization of node embeddings and predicted anomalies\")\n",
    "colors = np.array([\"#377eb8\", \"#ff7f00\"])\n",
    "axis = ax.scatter(account_embeddings_reduced_dim[:, 0], account_embeddings_reduced_dim[:, 1],\n",
    "color=colors[(y_pred + 1) // 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359ad3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fdbc19",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=12).fit(account_embeddings_reduced_dim)\n",
    "clusters = kmeans.labels_\n",
    "\n",
    "\n",
    "fraud_acc_index = mapping['Account']['account-4398046511937']\n",
    "\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot()\n",
    "fig.suptitle(\"Visualization of node embeddings and clusters\")\n",
    "colors = np.array([\"#ff7f00\"] * 12)\n",
    "colors[4] = \"#377eb8\"\n",
    "ax.scatter(account_embeddings_reduced_dim[:, 0], account_embeddings_reduced_dim[:, 1], color=colors[clusters  % 12])\n",
    "ax.scatter(account_embeddings_reduced_dim[fraud_acc_index, 0], account_embeddings_reduced_dim[fraud_acc_index, 1], color='r')\n",
    "for index, key in enumerate(list(mapping['Account'].keys())[:15]):\n",
    "    ax.annotate(key, (account_embeddings_reduced_dim[index, 0], account_embeddings_reduced_dim[index, 1])) \n",
    "ax.annotate('account-4398046511937', (account_embeddings_reduced_dim[fraud_acc_index, 0], account_embeddings_reduced_dim[fraud_acc_index, 1]))\n",
    "axis = ax.set(xlim=(4, 11), ylim=(2, 9))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
